{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa9c961",
   "metadata": {},
   "source": [
    "# Topic Modeling - LSA (Latent Semantic Analysis)\n",
    "\n",
    "https://wikidocs.net/24949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0118715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71453f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sample : 11314\n"
     ]
    }
   ],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers','footers','quotes'))\n",
    "documents = dataset.data\n",
    "\n",
    "print(f\" sample : {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d46b0a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62e5bfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e170f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb75a68e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03a1050e",
   "metadata": {},
   "source": [
    "## `text preprocessing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09d3fb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well i'm not sure about the story nad it did s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although I realize that principle is not one o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document\n",
       "0  Well i'm not sure about the story nad it did s...\n",
       "1  \\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...\n",
       "2  Although I realize that principle is not one o..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news_df = pd.DataFrame({'document':documents})\n",
    "display(news_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "776c0c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_22024\\1489621687.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  news_df['clean_doc'] = news_df['document'].str.replace('[^a-zA-Z]', ' ')\n"
     ]
    }
   ],
   "source": [
    "news_df['clean_doc'] = news_df['document'].str.replace('[^a-zA-Z]', ' ')\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3838b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['document'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c256ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yeah expect people read actually accept hard atheism need little leap faith jimmy your logic runs steam sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway maybe start newsgroup atheist hard bummin much forget your flintstone chewables bake timmons'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['clean_doc'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17202ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 가져오기\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "tokenized_doc= news_df['clean_doc'].apply(lambda x: x.split())\n",
    "tokenzied_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1adee4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yeah', 'expect', 'people', 'read', 'actually', 'accept', 'hard', 'atheism', 'need', 'little', 'leap', 'faith', 'jimmy', 'logic', 'runs', 'steam', 'sorry', 'pity', 'sorry', 'feelings', 'denial', 'faith', 'need', 'well', 'pretend', 'happily', 'ever', 'anyway', 'maybe', 'start', 'newsgroup', 'atheist', 'hard', 'bummin', 'much', 'forget', 'flintstone', 'chewables', 'bake', 'timmons']\n"
     ]
    }
   ],
   "source": [
    "print(tokenzied_doc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692c97e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d67dfb3d",
   "metadata": {},
   "source": [
    "##  `TF-IDF 행렬 만들기`\n",
    "\n",
    "\n",
    "    - 불용어 제거를 위해 토큰화 작업을 수행했지만, TfidfVectorizer는 기본적으로 토큰화가 되어있지 않은 텍스트 데이터를 입력으로 사용함\n",
    "    - TfidfVectorizer를 사용해서 TF-IDF 행렬을 만들기 위해서 토큰화 작업을 역으로 취소하는 작업 수행 \n",
    "     => 역토큰화(Detokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b21d30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "detokenzied_doc = []\n",
    "for i in range(len(news_df)):\n",
    "    t = ' '.join(tokenized_doc[i])\n",
    "    detokenzied_doc.append(t)\n",
    "    \n",
    "news_df['clean_doc'] = detokenzied_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3241469d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yeah expect people read actually accept hard atheism need little leap faith jimmy your logic runs steam sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway maybe start newsgroup atheist hard bummin much forget your flintstone chewables bake timmons'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['clean_doc'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c29c8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 행렬의 크기 : (11314, 1000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000,\n",
    "                             max_df = 0.5, smooth_idf=True)\n",
    "\n",
    "X = vectorizer.fit_transform(news_df['clean_doc'])\n",
    "\n",
    "print(f\"TF-IDF 행렬의 크기 : {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5114346f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db6ff98e",
   "metadata": {},
   "source": [
    "## `Topic Modeling`\n",
    "\n",
    "- TruncatedSVD 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96644b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f41ff08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_model = TruncatedSVD(n_components=20, algorithm='randomized', n_iter=100, random_state=122)\n",
    "svd_model.fit(X)\n",
    "len(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84f50910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4c5422e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ability', 'able', 'accept', 'access', 'according', 'account',\n",
       "       'action', 'actions', 'actual', 'actually', 'added', 'addition',\n",
       "       'additional', 'address', 'administration', 'advance', 'advice',\n",
       "       'agencies', 'agree', 'algorithm', 'allow', 'allowed', 'allows',\n",
       "       'amendment', 'america', 'american', 'americans', 'analysis',\n",
       "       'angeles', 'anonymous', 'answer', 'answers', 'anti', 'anybody',\n",
       "       'apparently', 'appear', 'appears', 'apple', 'application',\n",
       "       'applications', 'apply', 'appreciate', 'appreciated', 'approach',\n",
       "       'appropriate', 'april', 'arab', 'archive', 'area', 'areas', 'aren',\n",
       "       'argument', 'arguments', 'armenia', 'armenian', 'armenians',\n",
       "       'arms', 'army', 'article', 'articles', 'asked', 'asking', 'assume',\n",
       "       'assuming', 'atheism', 'atheists', 'attack', 'attempt', 'author',\n",
       "       'authority', 'available', 'average', 'avoid', 'away', 'background',\n",
       "       'base', 'baseball', 'based', 'basic', 'basically', 'basis',\n",
       "       'begin', 'beginning', 'belief', 'beliefs', 'believe', 'best',\n",
       "       'better', 'bible', 'bike', 'bios', 'bits', 'black', 'block',\n",
       "       'blood', 'blue', 'board', 'body', 'book', 'books', 'boston',\n",
       "       'bought', 'break', 'bring', 'brought', 'build', 'building',\n",
       "       'built', 'business', 'cable', 'california', 'called', 'calling',\n",
       "       'calls', 'came', 'canada', 'card', 'cards', 'care', 'carry',\n",
       "       'cars', 'case', 'cases', 'cause', 'center', 'certain', 'certainly',\n",
       "       'chance', 'change', 'changed', 'changes', 'char', 'character',\n",
       "       'cheap', 'check', 'chicago', 'child', 'children', 'chip', 'chips',\n",
       "       'choice', 'christ', 'christian', 'christianity', 'christians',\n",
       "       'church', 'citizens', 'city', 'civil', 'claim', 'claims', 'class',\n",
       "       'clear', 'clearly', 'clinton', 'clipper', 'clock', 'close', 'code',\n",
       "       'color', 'colorado', 'colors', 'come', 'comes', 'coming',\n",
       "       'command', 'comment', 'comments', 'commercial', 'committee',\n",
       "       'common', 'communications', 'community', 'comp', 'companies',\n",
       "       'company', 'complete', 'completely', 'computer', 'conclusion',\n",
       "       'condition', 'conference', 'congress', 'consider', 'considered',\n",
       "       'considering', 'contact', 'contains', 'context', 'continue',\n",
       "       'contrib', 'control', 'controller', 'convert', 'copy', 'correct',\n",
       "       'cost', 'costs', 'couldn', 'count', 'countries', 'country',\n",
       "       'couple', 'course', 'court', 'cover', 'create', 'created', 'crime',\n",
       "       'criminals', 'cross', 'current', 'currently', 'data', 'date',\n",
       "       'dave', 'david', 'days', 'dead', 'deal', 'death', 'decided',\n",
       "       'decision', 'default', 'defense', 'define', 'deleted',\n",
       "       'department', 'described', 'description', 'design', 'designed',\n",
       "       'details', 'detroit', 'developed', 'development', 'device',\n",
       "       'devices', 'didn', 'died', 'difference', 'different', 'difficult',\n",
       "       'digital', 'direct', 'directly', 'directory', 'discussion',\n",
       "       'disease', 'disk', 'disks', 'display', 'distribution', 'division',\n",
       "       'doctor', 'does', 'doesn', 'doing', 'door', 'double', 'doubt',\n",
       "       'draw', 'drive', 'driver', 'drivers', 'drives', 'driving', 'drug',\n",
       "       'drugs', 'earlier', 'early', 'earth', 'easily', 'east', 'easy',\n",
       "       'education', 'effect', 'effective', 'effort', 'electronic',\n",
       "       'email', 'encryption', 'enforcement', 'engine', 'entire', 'entry',\n",
       "       'environment', 'equipment', 'error', 'errors', 'escrow',\n",
       "       'especially', 'event', 'events', 'evidence', 'exactly', 'example',\n",
       "       'excellent', 'exist', 'existence', 'exists', 'expect', 'expected',\n",
       "       'expensive', 'experience', 'explain', 'export', 'extra', 'face',\n",
       "       'fact', 'fairly', 'faith', 'fall', 'false', 'family', 'fast',\n",
       "       'faster', 'father', 'features', 'federal', 'feel', 'field',\n",
       "       'figure', 'file', 'files', 'final', 'finally', 'fine', 'firearms',\n",
       "       'floppy', 'folks', 'follow', 'following', 'font', 'fonts', 'food',\n",
       "       'force', 'forget', 'form', 'format', 'free', 'freedom', 'friend',\n",
       "       'friends', 'fully', 'function', 'functions', 'future', 'game',\n",
       "       'games', 'gave', 'general', 'generally', 'genocide', 'germany',\n",
       "       'gets', 'getting', 'given', 'gives', 'giving', 'goal', 'goals',\n",
       "       'goes', 'going', 'gone', 'good', 'government', 'graphics', 'great',\n",
       "       'greatly', 'greek', 'ground', 'group', 'groups', 'guess', 'guns',\n",
       "       'guys', 'half', 'hand', 'handle', 'hands', 'happen', 'happened',\n",
       "       'happens', 'happy', 'hard', 'hardware', 'haven', 'having', 'head',\n",
       "       'health', 'hear', 'heard', 'held', 'hell', 'hello', 'help', 'high',\n",
       "       'higher', 'history', 'hockey', 'hold', 'holy', 'home', 'hope',\n",
       "       'hours', 'house', 'human', 'idea', 'ideas', 'image', 'images',\n",
       "       'imagine', 'important', 'include', 'included', 'includes',\n",
       "       'including', 'increase', 'independent', 'individual', 'info',\n",
       "       'information', 'input', 'inside', 'installed', 'instead',\n",
       "       'institute', 'insurance', 'intended', 'interested', 'interesting',\n",
       "       'interface', 'internal', 'international', 'internet', 'involved',\n",
       "       'israel', 'israeli', 'issue', 'issues', 'james', 'jesus', 'jewish',\n",
       "       'jews', 'jobs', 'john', 'jpeg', 'just', 'kept', 'keyboard', 'keys',\n",
       "       'kill', 'killed', 'killing', 'kind', 'king', 'knew', 'know',\n",
       "       'knowledge', 'known', 'knows', 'lack', 'land', 'language', 'large',\n",
       "       'late', 'later', 'latest', 'launch', 'laws', 'lead', 'league',\n",
       "       'learn', 'leave', 'left', 'legal', 'letter', 'level', 'library',\n",
       "       'license', 'life', 'light', 'like', 'likely', 'limited', 'line',\n",
       "       'lines', 'list', 'little', 'live', 'lives', 'living', 'local',\n",
       "       'logic', 'long', 'longer', 'look', 'looked', 'looking', 'looks',\n",
       "       'lord', 'lost', 'lots', 'love', 'lower', 'lunar', 'machine',\n",
       "       'machines', 'magazine', 'mail', 'mailing', 'main', 'major',\n",
       "       'majority', 'make', 'makes', 'making', 'manager', 'manual',\n",
       "       'march', 'mark', 'market', 'mass', 'master', 'material', 'matter',\n",
       "       'matthew', 'maybe', 'mean', 'meaning', 'means', 'media', 'medical',\n",
       "       'member', 'members', 'memory', 'mention', 'mentioned', 'message',\n",
       "       'messages', 'method', 'michael', 'middle', 'mike', 'miles',\n",
       "       'military', 'million', 'mind', 'minutes', 'misc', 'mission',\n",
       "       'mode', 'model', 'models', 'modem', 'modern', 'money', 'monitor',\n",
       "       'month', 'months', 'moon', 'moral', 'mother', 'motif', 'mouse',\n",
       "       'multi', 'multiple', 'muslim', 'names', 'nasa', 'national',\n",
       "       'natural', 'nature', 'near', 'necessary', 'need', 'needed',\n",
       "       'needs', 'network', 'news', 'newsgroup', 'nice', 'night', 'normal',\n",
       "       'north', 'note', 'null', 'number', 'numbers', 'object',\n",
       "       'objective', 'obvious', 'obviously', 'offer', 'offers', 'office',\n",
       "       'official', 'ones', 'open', 'operation', 'opinion', 'opinions',\n",
       "       'option', 'options', 'orbit', 'order', 'organization', 'original',\n",
       "       'output', 'outside', 'package', 'page', 'paid', 'pain', 'paper',\n",
       "       'particular', 'particularly', 'parts', 'party', 'pass', 'passed',\n",
       "       'past', 'patients', 'paul', 'peace', 'people', 'perfect',\n",
       "       'performance', 'period', 'person', 'personal', 'peter', 'phone',\n",
       "       'physical', 'pick', 'picture', 'pittsburgh', 'place', 'places',\n",
       "       'plan', 'play', 'played', 'player', 'players', 'playing', 'plus',\n",
       "       'point', 'points', 'police', 'policy', 'political', 'poor',\n",
       "       'population', 'port', 'position', 'possible', 'possibly', 'post',\n",
       "       'posted', 'posting', 'posts', 'postscript', 'power', 'practice',\n",
       "       'present', 'president', 'press', 'pretty', 'prevent', 'previous',\n",
       "       'price', 'print', 'printer', 'privacy', 'private', 'probably',\n",
       "       'problem', 'problems', 'process', 'processing', 'produce',\n",
       "       'product', 'products', 'program', 'programming', 'programs',\n",
       "       'project', 'protect', 'protection', 'prove', 'provide', 'provided',\n",
       "       'provides', 'public', 'published', 'purpose', 'quality',\n",
       "       'question', 'questions', 'quite', 'quote', 'radio', 'range',\n",
       "       'rate', 'rates', 'read', 'reading', 'real', 'reality', 'realize',\n",
       "       'really', 'reason', 'reasonable', 'reasons', 'receive', 'received',\n",
       "       'recent', 'recently', 'record', 'reference', 'references',\n",
       "       'regarding', 'regular', 'related', 'release', 'religion',\n",
       "       'religious', 'remember', 'reply', 'report', 'reported', 'reports',\n",
       "       'request', 'require', 'required', 'requires', 'research',\n",
       "       'resource', 'resources', 'respect', 'response', 'rest', 'result',\n",
       "       'results', 'return', 'right', 'rights', 'risk', 'road', 'robert',\n",
       "       'room', 'round', 'rule', 'rules', 'running', 'runs', 'russia',\n",
       "       'russian', 'safe', 'safety', 'said', 'sale', 'satellite', 'save',\n",
       "       'saying', 'says', 'school', 'science', 'scientific', 'screen',\n",
       "       'scsi', 'search', 'season', 'second', 'secret', 'section',\n",
       "       'secure', 'security', 'seen', 'self', 'sell', 'send', 'sense',\n",
       "       'sent', 'serial', 'series', 'seriously', 'server', 'service',\n",
       "       'services', 'setting', 'shall', 'shipping', 'short', 'shot',\n",
       "       'shouldn', 'shows', 'shuttle', 'similar', 'simple', 'simply',\n",
       "       'single', 'site', 'sites', 'situation', 'size', 'slow', 'small',\n",
       "       'smith', 'social', 'society', 'software', 'sold', 'soldiers',\n",
       "       'solution', 'somebody', 'soon', 'sorry', 'sort', 'sound', 'sounds',\n",
       "       'source', 'sources', 'south', 'soviet', 'space', 'speak',\n",
       "       'special', 'specific', 'specifically', 'speed', 'spirit', 'stand',\n",
       "       'standard', 'standards', 'start', 'started', 'starting', 'state',\n",
       "       'stated', 'statement', 'states', 'station', 'stay', 'step',\n",
       "       'stephanopoulos', 'steve', 'stop', 'story', 'stream', 'street',\n",
       "       'strong', 'studies', 'study', 'stuff', 'stupid', 'subject',\n",
       "       'suggest', 'suggestions', 'summer', 'supply', 'support',\n",
       "       'supported', 'supports', 'suppose', 'supposed', 'sure', 'surface',\n",
       "       'suspect', 'switch', 'systems', 'table', 'taken', 'takes',\n",
       "       'taking', 'talk', 'talking', 'tape', 'team', 'teams', 'technical',\n",
       "       'technology', 'tell', 'term', 'terms', 'test', 'text', 'thank',\n",
       "       'thanks', 'theory', 'thing', 'things', 'think', 'thinking',\n",
       "       'thought', 'time', 'times', 'title', 'today', 'told', 'took',\n",
       "       'tools', 'toronto', 'total', 'town', 'trade', 'traffic',\n",
       "       'transfer', 'tried', 'trouble', 'true', 'trust', 'truth', 'trying',\n",
       "       'turkey', 'turkish', 'turks', 'turn', 'turned', 'type', 'types',\n",
       "       'understand', 'understanding', 'unfortunately', 'unit', 'united',\n",
       "       'universe', 'university', 'unix', 'unless', 'used', 'useful',\n",
       "       'usenet', 'user', 'users', 'uses', 'using', 'usually', 'value',\n",
       "       'values', 'vancouver', 'various', 'vehicle', 'version', 'versions',\n",
       "       'video', 'view', 'voice', 'volume', 'wait', 'want', 'wanted',\n",
       "       'wants', 'washington', 'wasn', 'watch', 'water', 'ways', 'weapon',\n",
       "       'weapons', 'week', 'weeks', 'went', 'west', 'western', 'white',\n",
       "       'wide', 'widget', 'wife', 'willing', 'window', 'windows', 'wire',\n",
       "       'wish', 'woman', 'women', 'wonder', 'wondering', 'word', 'words',\n",
       "       'work', 'worked', 'working', 'works', 'world', 'worse', 'worth',\n",
       "       'wouldn', 'write', 'writing', 'written', 'wrong', 'wrote', 'xterm',\n",
       "       'yeah', 'year', 'years', 'york', 'young'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names_out()\n",
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6a62c738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " topic : 1 : [('just', 0.20887), ('like', 0.20469), ('know', 0.19349), ('people', 0.18318), ('think', 0.1697)]\n",
      " topic : 2 : [('thanks', 0.32763), ('windows', 0.28786), ('card', 0.18019), ('drive', 0.16864), ('mail', 0.15261)]\n",
      " topic : 3 : [('game', 0.34011), ('team', 0.30311), ('year', 0.26894), ('games', 0.23784), ('drive', 0.17472)]\n",
      " topic : 4 : [('drive', 0.46159), ('scsi', 0.17188), ('disk', 0.14451), ('hard', 0.13805), ('problem', 0.12763)]\n",
      " topic : 5 : [('drive', 0.39993), ('know', 0.28768), ('thanks', 0.24917), ('does', 0.24678), ('just', 0.17387)]\n",
      " topic : 6 : [('just', 0.55559), ('like', 0.23559), ('windows', 0.23078), ('know', 0.15795), ('does', 0.11156)]\n",
      " topic : 7 : [('just', 0.43264), ('like', 0.22858), ('mail', 0.15052), ('bike', 0.11698), ('thanks', 0.10025)]\n",
      " topic : 8 : [('does', 0.39692), ('know', 0.25192), ('chip', 0.22492), ('like', 0.17824), ('card', 0.15695)]\n",
      " topic : 9 : [('like', 0.42065), ('card', 0.32249), ('sale', 0.20267), ('video', 0.1571), ('offer', 0.14119)]\n",
      " topic : 10 : [('like', 0.61166), ('drive', 0.23998), ('file', 0.13257), ('files', 0.09233), ('sounds', 0.08533)]\n",
      " topic : 11 : [('people', 0.44189), ('like', 0.25647), ('thanks', 0.19072), ('card', 0.18615), ('government', 0.18341)]\n",
      " topic : 12 : [('think', 0.66867), ('good', 0.25984), ('thanks', 0.11249), ('need', 0.10479), ('chip', 0.09178)]\n",
      " topic : 13 : [('think', 0.36273), ('does', 0.22264), ('just', 0.21194), ('mail', 0.12875), ('like', 0.12095)]\n",
      " topic : 14 : [('know', 0.36546), ('good', 0.30975), ('people', 0.27825), ('windows', 0.2729), ('file', 0.20088)]\n",
      " topic : 15 : [('space', 0.4519), ('know', 0.31141), ('think', 0.18571), ('nasa', 0.1711), ('card', 0.11724)]\n",
      " topic : 16 : [('does', 0.42324), ('israel', 0.31948), ('think', 0.26996), ('right', 0.1863), ('israeli', 0.17007)]\n",
      " topic : 17 : [('good', 0.41859), ('space', 0.27501), ('card', 0.1855), ('does', 0.16985), ('thanks', 0.16633)]\n",
      " topic : 18 : [('people', 0.5173), ('does', 0.25965), ('window', 0.21657), ('problem', 0.19057), ('space', 0.12958)]\n",
      " topic : 19 : [('right', 0.36578), ('bike', 0.31154), ('time', 0.19438), ('windows', 0.18916), ('space', 0.1777)]\n",
      " topic : 20 : [('file', 0.53334), ('problem', 0.20198), ('files', 0.19583), ('need', 0.18333), ('time', 0.15802)]\n"
     ]
    }
   ],
   "source": [
    "def get_topics(components, feature_names, n=5):\n",
    "    for idx, topic in enumerate(components):\n",
    "        print(f\" topic : {idx+1} : {[(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n-1:-1]]}\")\n",
    "        \n",
    "    \n",
    "get_topics(svd_model.components_,terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03831339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01409818,  0.04787982,  0.02051048, ...,  0.07483329,\n",
       "         0.01377606,  0.01712888],\n",
       "       [-0.00521437,  0.01742255, -0.01542793, ..., -0.06266609,\n",
       "        -0.01075043, -0.01888594],\n",
       "       [ 0.00243598, -0.00142246, -0.01848973, ...,  0.05823359,\n",
       "         0.02412148,  0.02038499],\n",
       "       ...,\n",
       "       [ 0.00746824, -0.00689738, -0.00963879, ..., -0.03316437,\n",
       "        -0.00649624, -0.0002525 ],\n",
       "       [ 0.00352545,  0.01029423, -0.01284824, ...,  0.01336511,\n",
       "        -0.01588696, -0.00127575],\n",
       "       [-0.00221751,  0.00855738,  0.00623428, ..., -0.05112369,\n",
       "        -0.00794476, -0.00491316]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VT 에 해당\n",
    "svd_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6a56f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[972, 971, 996, ..., 324, 677, 323],\n",
       "       [677, 365, 437, ..., 896,  89, 746],\n",
       "       [437, 458, 438, ..., 971, 255, 626],\n",
       "       [458, 746, 677, ..., 116, 826, 365],\n",
       "       [458, 442, 116, ..., 893, 437, 255]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd47f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
